

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torchreid.data &mdash; torchreid 1.3.5 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="torchreid.engine" href="engine.html" />
    <link rel="prev" title="Evaluation" href="../evaluation.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> torchreid
          

          
          </a>

          
            
            
              <div class="version">
                1.3.5
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../user_guide.html">How-to</a></li>
<li class="toctree-l1"><a class="reference internal" href="../datasets.html">Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../evaluation.html">Evaluation</a></li>
</ul>
<p class="caption"><span class="caption-text">Package Reference</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">torchreid.data</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#module-torchreid.data.datamanager">Data Manager</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-torchreid.data.sampler">Sampler</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-torchreid.data.transforms">Transforms</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-torchreid.data.datasets.dataset">Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-torchreid.data.datasets.image.market1501">Image Datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-torchreid.data.datasets.video.mars">Video Datasets</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="engine.html">torchreid.engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="losses.html">torchreid.losses</a></li>
<li class="toctree-l1"><a class="reference internal" href="metrics.html">torchreid.metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="models.html">torchreid.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">torchreid.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">torchreid.utils</a></li>
</ul>
<p class="caption"><span class="caption-text">Resources</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../AWESOME_REID.html">Awesome-ReID</a></li>
<li class="toctree-l1"><a class="reference internal" href="../MODEL_ZOO.html">Model Zoo</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">torchreid</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>torchreid.data</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/pkg/data.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="torchreid-data">
<span id="id1"></span><h1>torchreid.data<a class="headerlink" href="#torchreid-data" title="Permalink to this headline">¶</a></h1>
<div class="section" id="module-torchreid.data.datamanager">
<span id="data-manager"></span><h2>Data Manager<a class="headerlink" href="#module-torchreid.data.datamanager" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchreid.data.datamanager.DataManager">
<em class="property">class </em><code class="sig-prename descclassname">torchreid.data.datamanager.</code><code class="sig-name descname">DataManager</code><span class="sig-paren">(</span><em class="sig-param">sources=None</em>, <em class="sig-param">targets=None</em>, <em class="sig-param">height=256</em>, <em class="sig-param">width=128</em>, <em class="sig-param">transforms='random_flip'</em>, <em class="sig-param">norm_mean=None</em>, <em class="sig-param">norm_std=None</em>, <em class="sig-param">use_gpu=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/datamanager.html#DataManager"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.datamanager.DataManager" title="Permalink to this definition">¶</a></dt>
<dd><p>Base data manager.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sources</strong> (<em>str</em><em> or </em><em>list</em>) – source dataset(s).</p></li>
<li><p><strong>targets</strong> (<em>str</em><em> or </em><em>list</em><em>, </em><em>optional</em>) – target dataset(s). If not given,
it equals to <code class="docutils literal notranslate"><span class="pre">sources</span></code>.</p></li>
<li><p><strong>height</strong> (<em>int</em><em>, </em><em>optional</em>) – target image height. Default is 256.</p></li>
<li><p><strong>width</strong> (<em>int</em><em>, </em><em>optional</em>) – target image width. Default is 128.</p></li>
<li><p><strong>transforms</strong> (<em>str</em><em> or </em><em>list of str</em><em>, </em><em>optional</em>) – transformations applied to model training.
Default is ‘random_flip’.</p></li>
<li><p><strong>norm_mean</strong> (<em>list</em><em> or </em><em>None</em><em>, </em><em>optional</em>) – data mean. Default is None (use imagenet mean).</p></li>
<li><p><strong>norm_std</strong> (<em>list</em><em> or </em><em>None</em><em>, </em><em>optional</em>) – data std. Default is None (use imagenet std).</p></li>
<li><p><strong>use_gpu</strong> (<em>bool</em><em>, </em><em>optional</em>) – use gpu. Default is True.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torchreid.data.datamanager.DataManager.fetch_test_loaders">
<code class="sig-name descname">fetch_test_loaders</code><span class="sig-paren">(</span><em class="sig-param">name</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/datamanager.html#DataManager.fetch_test_loaders"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.datamanager.DataManager.fetch_test_loaders" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns query and gallery of a test dataset, each containing
tuples of (img_path(s), pid, camid).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>name</strong> (<em>str</em>) – dataset name.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torchreid.data.datamanager.DataManager.num_train_cams">
<em class="property">property </em><code class="sig-name descname">num_train_cams</code><a class="headerlink" href="#torchreid.data.datamanager.DataManager.num_train_cams" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the number of training cameras.</p>
</dd></dl>

<dl class="method">
<dt id="torchreid.data.datamanager.DataManager.num_train_pids">
<em class="property">property </em><code class="sig-name descname">num_train_pids</code><a class="headerlink" href="#torchreid.data.datamanager.DataManager.num_train_pids" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the number of training person identities.</p>
</dd></dl>

<dl class="method">
<dt id="torchreid.data.datamanager.DataManager.preprocess_pil_img">
<code class="sig-name descname">preprocess_pil_img</code><span class="sig-paren">(</span><em class="sig-param">img</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/datamanager.html#DataManager.preprocess_pil_img"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.datamanager.DataManager.preprocess_pil_img" title="Permalink to this definition">¶</a></dt>
<dd><p>Transforms a PIL image to torch tensor for testing.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchreid.data.datamanager.ImageDataManager">
<em class="property">class </em><code class="sig-prename descclassname">torchreid.data.datamanager.</code><code class="sig-name descname">ImageDataManager</code><span class="sig-paren">(</span><em class="sig-param">root=''</em>, <em class="sig-param">sources=None</em>, <em class="sig-param">targets=None</em>, <em class="sig-param">height=256</em>, <em class="sig-param">width=128</em>, <em class="sig-param">transforms='random_flip'</em>, <em class="sig-param">k_tfm=1</em>, <em class="sig-param">norm_mean=None</em>, <em class="sig-param">norm_std=None</em>, <em class="sig-param">use_gpu=True</em>, <em class="sig-param">split_id=0</em>, <em class="sig-param">combineall=False</em>, <em class="sig-param">load_train_targets=False</em>, <em class="sig-param">batch_size_train=32</em>, <em class="sig-param">batch_size_test=32</em>, <em class="sig-param">workers=4</em>, <em class="sig-param">num_instances=4</em>, <em class="sig-param">num_cams=1</em>, <em class="sig-param">num_datasets=1</em>, <em class="sig-param">train_sampler='RandomSampler'</em>, <em class="sig-param">train_sampler_t='RandomSampler'</em>, <em class="sig-param">cuhk03_labeled=False</em>, <em class="sig-param">cuhk03_classic_split=False</em>, <em class="sig-param">market1501_500k=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/datamanager.html#ImageDataManager"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.datamanager.ImageDataManager" title="Permalink to this definition">¶</a></dt>
<dd><p>Image data manager.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> (<em>str</em>) – root path to datasets.</p></li>
<li><p><strong>sources</strong> (<em>str</em><em> or </em><em>list</em>) – source dataset(s).</p></li>
<li><p><strong>targets</strong> (<em>str</em><em> or </em><em>list</em><em>, </em><em>optional</em>) – target dataset(s). If not given,
it equals to <code class="docutils literal notranslate"><span class="pre">sources</span></code>.</p></li>
<li><p><strong>height</strong> (<em>int</em><em>, </em><em>optional</em>) – target image height. Default is 256.</p></li>
<li><p><strong>width</strong> (<em>int</em><em>, </em><em>optional</em>) – target image width. Default is 128.</p></li>
<li><p><strong>transforms</strong> (<em>str</em><em> or </em><em>list of str</em><em>, </em><em>optional</em>) – transformations applied to model training.
Default is ‘random_flip’.</p></li>
<li><p><strong>k_tfm</strong> (<em>int</em>) – number of times to apply augmentation to an image
independently. If k_tfm &gt; 1, the transform function will be
applied k_tfm times to an image. This variable will only be
useful for training and is currently valid for image datasets only.</p></li>
<li><p><strong>norm_mean</strong> (<em>list</em><em> or </em><em>None</em><em>, </em><em>optional</em>) – data mean. Default is None (use imagenet mean).</p></li>
<li><p><strong>norm_std</strong> (<em>list</em><em> or </em><em>None</em><em>, </em><em>optional</em>) – data std. Default is None (use imagenet std).</p></li>
<li><p><strong>use_gpu</strong> (<em>bool</em><em>, </em><em>optional</em>) – use gpu. Default is True.</p></li>
<li><p><strong>split_id</strong> (<em>int</em><em>, </em><em>optional</em>) – split id (<em>0-based</em>). Default is 0.</p></li>
<li><p><strong>combineall</strong> (<em>bool</em><em>, </em><em>optional</em>) – combine train, query and gallery in a dataset for
training. Default is False.</p></li>
<li><p><strong>load_train_targets</strong> (<em>bool</em><em>, </em><em>optional</em>) – construct train-loader for target datasets.
Default is False. This is useful for domain adaptation research.</p></li>
<li><p><strong>batch_size_train</strong> (<em>int</em><em>, </em><em>optional</em>) – number of images in a training batch. Default is 32.</p></li>
<li><p><strong>batch_size_test</strong> (<em>int</em><em>, </em><em>optional</em>) – number of images in a test batch. Default is 32.</p></li>
<li><p><strong>workers</strong> (<em>int</em><em>, </em><em>optional</em>) – number of workers. Default is 4.</p></li>
<li><p><strong>num_instances</strong> (<em>int</em><em>, </em><em>optional</em>) – number of instances per identity in a batch.
Default is 4.</p></li>
<li><p><strong>num_cams</strong> (<em>int</em><em>, </em><em>optional</em>) – number of cameras to sample in a batch (when using
<code class="docutils literal notranslate"><span class="pre">RandomDomainSampler</span></code>). Default is 1.</p></li>
<li><p><strong>num_datasets</strong> (<em>int</em><em>, </em><em>optional</em>) – number of datasets to sample in a batch (when
using <code class="docutils literal notranslate"><span class="pre">RandomDatasetSampler</span></code>). Default is 1.</p></li>
<li><p><strong>train_sampler</strong> (<em>str</em><em>, </em><em>optional</em>) – sampler. Default is RandomSampler.</p></li>
<li><p><strong>train_sampler_t</strong> (<em>str</em><em>, </em><em>optional</em>) – sampler for target train loader. Default is RandomSampler.</p></li>
<li><p><strong>cuhk03_labeled</strong> (<em>bool</em><em>, </em><em>optional</em>) – use cuhk03 labeled images.
Default is False (defaul is to use detected images).</p></li>
<li><p><strong>cuhk03_classic_split</strong> (<em>bool</em><em>, </em><em>optional</em>) – use the classic split in cuhk03.
Default is False.</p></li>
<li><p><strong>market1501_500k</strong> (<em>bool</em><em>, </em><em>optional</em>) – add 500K distractors to the gallery
set in market1501. Default is False.</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">datamanager</span> <span class="o">=</span> <span class="n">torchreid</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">ImageDataManager</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="s1">&#39;path/to/reid-data&#39;</span><span class="p">,</span>
    <span class="n">sources</span><span class="o">=</span><span class="s1">&#39;market1501&#39;</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
    <span class="n">batch_size_train</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
    <span class="n">batch_size_test</span><span class="o">=</span><span class="mi">100</span>
<span class="p">)</span>

<span class="c1"># return train loader of source data</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">datamanager</span><span class="o">.</span><span class="n">train_loader</span>

<span class="c1"># return test loader of target data</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">datamanager</span><span class="o">.</span><span class="n">test_loader</span>

<span class="c1"># return train loader of target data</span>
<span class="n">train_loader_t</span> <span class="o">=</span> <span class="n">datamanager</span><span class="o">.</span><span class="n">train_loader_t</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="torchreid.data.datamanager.VideoDataManager">
<em class="property">class </em><code class="sig-prename descclassname">torchreid.data.datamanager.</code><code class="sig-name descname">VideoDataManager</code><span class="sig-paren">(</span><em class="sig-param">root=''</em>, <em class="sig-param">sources=None</em>, <em class="sig-param">targets=None</em>, <em class="sig-param">height=256</em>, <em class="sig-param">width=128</em>, <em class="sig-param">transforms='random_flip'</em>, <em class="sig-param">norm_mean=None</em>, <em class="sig-param">norm_std=None</em>, <em class="sig-param">use_gpu=True</em>, <em class="sig-param">split_id=0</em>, <em class="sig-param">combineall=False</em>, <em class="sig-param">batch_size_train=3</em>, <em class="sig-param">batch_size_test=3</em>, <em class="sig-param">workers=4</em>, <em class="sig-param">num_instances=4</em>, <em class="sig-param">num_cams=1</em>, <em class="sig-param">num_datasets=1</em>, <em class="sig-param">train_sampler='RandomSampler'</em>, <em class="sig-param">seq_len=15</em>, <em class="sig-param">sample_method='evenly'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/datamanager.html#VideoDataManager"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.datamanager.VideoDataManager" title="Permalink to this definition">¶</a></dt>
<dd><p>Video data manager.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> (<em>str</em>) – root path to datasets.</p></li>
<li><p><strong>sources</strong> (<em>str</em><em> or </em><em>list</em>) – source dataset(s).</p></li>
<li><p><strong>targets</strong> (<em>str</em><em> or </em><em>list</em><em>, </em><em>optional</em>) – target dataset(s). If not given,
it equals to <code class="docutils literal notranslate"><span class="pre">sources</span></code>.</p></li>
<li><p><strong>height</strong> (<em>int</em><em>, </em><em>optional</em>) – target image height. Default is 256.</p></li>
<li><p><strong>width</strong> (<em>int</em><em>, </em><em>optional</em>) – target image width. Default is 128.</p></li>
<li><p><strong>transforms</strong> (<em>str</em><em> or </em><em>list of str</em><em>, </em><em>optional</em>) – transformations applied to model training.
Default is ‘random_flip’.</p></li>
<li><p><strong>norm_mean</strong> (<em>list</em><em> or </em><em>None</em><em>, </em><em>optional</em>) – data mean. Default is None (use imagenet mean).</p></li>
<li><p><strong>norm_std</strong> (<em>list</em><em> or </em><em>None</em><em>, </em><em>optional</em>) – data std. Default is None (use imagenet std).</p></li>
<li><p><strong>use_gpu</strong> (<em>bool</em><em>, </em><em>optional</em>) – use gpu. Default is True.</p></li>
<li><p><strong>split_id</strong> (<em>int</em><em>, </em><em>optional</em>) – split id (<em>0-based</em>). Default is 0.</p></li>
<li><p><strong>combineall</strong> (<em>bool</em><em>, </em><em>optional</em>) – combine train, query and gallery in a dataset for
training. Default is False.</p></li>
<li><p><strong>batch_size_train</strong> (<em>int</em><em>, </em><em>optional</em>) – number of tracklets in a training batch. Default is 3.</p></li>
<li><p><strong>batch_size_test</strong> (<em>int</em><em>, </em><em>optional</em>) – number of tracklets in a test batch. Default is 3.</p></li>
<li><p><strong>workers</strong> (<em>int</em><em>, </em><em>optional</em>) – number of workers. Default is 4.</p></li>
<li><p><strong>num_instances</strong> (<em>int</em><em>, </em><em>optional</em>) – number of instances per identity in a batch.
Default is 4.</p></li>
<li><p><strong>num_cams</strong> (<em>int</em><em>, </em><em>optional</em>) – number of cameras to sample in a batch (when using
<code class="docutils literal notranslate"><span class="pre">RandomDomainSampler</span></code>). Default is 1.</p></li>
<li><p><strong>num_datasets</strong> (<em>int</em><em>, </em><em>optional</em>) – number of datasets to sample in a batch (when
using <code class="docutils literal notranslate"><span class="pre">RandomDatasetSampler</span></code>). Default is 1.</p></li>
<li><p><strong>train_sampler</strong> (<em>str</em><em>, </em><em>optional</em>) – sampler. Default is RandomSampler.</p></li>
<li><p><strong>seq_len</strong> (<em>int</em><em>, </em><em>optional</em>) – how many images to sample in a tracklet. Default is 15.</p></li>
<li><p><strong>sample_method</strong> (<em>str</em><em>, </em><em>optional</em>) – how to sample images in a tracklet. Default is “evenly”.
Choices are [“evenly”, “random”, “all”]. “evenly” and “random” will sample <code class="docutils literal notranslate"><span class="pre">seq_len</span></code>
images in a tracklet while “all” samples all images in a tracklet, where the batch size
needs to be set to 1.</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">datamanager</span> <span class="o">=</span> <span class="n">torchreid</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">VideoDataManager</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="s1">&#39;path/to/reid-data&#39;</span><span class="p">,</span>
    <span class="n">sources</span><span class="o">=</span><span class="s1">&#39;mars&#39;</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
    <span class="n">batch_size_train</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">batch_size_test</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">seq_len</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
    <span class="n">sample_method</span><span class="o">=</span><span class="s1">&#39;evenly&#39;</span>
<span class="p">)</span>

<span class="c1"># return train loader of source data</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">datamanager</span><span class="o">.</span><span class="n">train_loader</span>

<span class="c1"># return test loader of target data</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">datamanager</span><span class="o">.</span><span class="n">test_loader</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The current implementation only supports image-like training. Therefore, each image in a
sampled tracklet will undergo independent transformation functions. To achieve tracklet-aware
training, you need to modify the transformation functions for video reid such that each function
applies the same operation to all images in a tracklet to keep consistency.</p>
</div>
</dd></dl>

</div>
<div class="section" id="module-torchreid.data.sampler">
<span id="sampler"></span><h2>Sampler<a class="headerlink" href="#module-torchreid.data.sampler" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchreid.data.sampler.RandomDatasetSampler">
<em class="property">class </em><code class="sig-prename descclassname">torchreid.data.sampler.</code><code class="sig-name descname">RandomDatasetSampler</code><span class="sig-paren">(</span><em class="sig-param">data_source</em>, <em class="sig-param">batch_size</em>, <em class="sig-param">n_dataset</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/sampler.html#RandomDatasetSampler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.sampler.RandomDatasetSampler" title="Permalink to this definition">¶</a></dt>
<dd><p>Random dataset sampler.</p>
<p>How does the sampling work:
1. Randomly sample N datasets (based on the “dsetid” label).
2. From each dataset, randomly sample K images.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_source</strong> (<em>list</em>) – contains tuples of (img_path(s), pid, camid, dsetid).</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – batch size.</p></li>
<li><p><strong>n_dataset</strong> (<em>int</em>) – number of datasets to sample in a batch.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="torchreid.data.sampler.RandomDomainSampler">
<em class="property">class </em><code class="sig-prename descclassname">torchreid.data.sampler.</code><code class="sig-name descname">RandomDomainSampler</code><span class="sig-paren">(</span><em class="sig-param">data_source</em>, <em class="sig-param">batch_size</em>, <em class="sig-param">n_domain</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/sampler.html#RandomDomainSampler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.sampler.RandomDomainSampler" title="Permalink to this definition">¶</a></dt>
<dd><p>Random domain sampler.</p>
<p>We consider each camera as a visual domain.</p>
<p>How does the sampling work:
1. Randomly sample N cameras (based on the “camid” label).
2. From each camera, randomly sample K images.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_source</strong> (<em>list</em>) – contains tuples of (img_path(s), pid, camid, dsetid).</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – batch size.</p></li>
<li><p><strong>n_domain</strong> (<em>int</em>) – number of cameras to sample in a batch.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="torchreid.data.sampler.RandomIdentitySampler">
<em class="property">class </em><code class="sig-prename descclassname">torchreid.data.sampler.</code><code class="sig-name descname">RandomIdentitySampler</code><span class="sig-paren">(</span><em class="sig-param">data_source</em>, <em class="sig-param">batch_size</em>, <em class="sig-param">num_instances</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/sampler.html#RandomIdentitySampler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.sampler.RandomIdentitySampler" title="Permalink to this definition">¶</a></dt>
<dd><p>Randomly samples N identities each with K instances.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_source</strong> (<em>list</em>) – contains tuples of (img_path(s), pid, camid, dsetid).</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – batch size.</p></li>
<li><p><strong>num_instances</strong> (<em>int</em>) – number of instances per identity in a batch.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="torchreid.data.sampler.build_train_sampler">
<code class="sig-prename descclassname">torchreid.data.sampler.</code><code class="sig-name descname">build_train_sampler</code><span class="sig-paren">(</span><em class="sig-param">data_source</em>, <em class="sig-param">train_sampler</em>, <em class="sig-param">batch_size=32</em>, <em class="sig-param">num_instances=4</em>, <em class="sig-param">num_cams=1</em>, <em class="sig-param">num_datasets=1</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/sampler.html#build_train_sampler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.sampler.build_train_sampler" title="Permalink to this definition">¶</a></dt>
<dd><p>Builds a training sampler.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_source</strong> (<em>list</em>) – contains tuples of (img_path(s), pid, camid).</p></li>
<li><p><strong>train_sampler</strong> (<em>str</em>) – sampler name (default: <code class="docutils literal notranslate"><span class="pre">RandomSampler</span></code>).</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>optional</em>) – batch size. Default is 32.</p></li>
<li><p><strong>num_instances</strong> (<em>int</em><em>, </em><em>optional</em>) – number of instances per identity in a
batch (when using <code class="docutils literal notranslate"><span class="pre">RandomIdentitySampler</span></code>). Default is 4.</p></li>
<li><p><strong>num_cams</strong> (<em>int</em><em>, </em><em>optional</em>) – number of cameras to sample in a batch (when using
<code class="docutils literal notranslate"><span class="pre">RandomDomainSampler</span></code>). Default is 1.</p></li>
<li><p><strong>num_datasets</strong> (<em>int</em><em>, </em><em>optional</em>) – number of datasets to sample in a batch (when
using <code class="docutils literal notranslate"><span class="pre">RandomDatasetSampler</span></code>). Default is 1.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-torchreid.data.transforms">
<span id="transforms"></span><h2>Transforms<a class="headerlink" href="#module-torchreid.data.transforms" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchreid.data.transforms.ColorAugmentation">
<em class="property">class </em><code class="sig-prename descclassname">torchreid.data.transforms.</code><code class="sig-name descname">ColorAugmentation</code><span class="sig-paren">(</span><em class="sig-param">p=0.5</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/transforms.html#ColorAugmentation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.transforms.ColorAugmentation" title="Permalink to this definition">¶</a></dt>
<dd><p>Randomly alters the intensities of RGB channels.</p>
<dl class="simple">
<dt>Reference:</dt><dd><p>Krizhevsky et al. ImageNet Classification with Deep ConvolutionalNeural
Networks. NIPS 2012.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>p</strong> (<em>float</em><em>, </em><em>optional</em>) – probability that this operation takes place.
Default is 0.5.</p>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="torchreid.data.transforms.Random2DTranslation">
<em class="property">class </em><code class="sig-prename descclassname">torchreid.data.transforms.</code><code class="sig-name descname">Random2DTranslation</code><span class="sig-paren">(</span><em class="sig-param">height</em>, <em class="sig-param">width</em>, <em class="sig-param">p=0.5</em>, <em class="sig-param">interpolation=2</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/transforms.html#Random2DTranslation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.transforms.Random2DTranslation" title="Permalink to this definition">¶</a></dt>
<dd><p>Randomly translates the input image with a probability.</p>
<p>Specifically, given a predefined shape (height, width), the input is first
resized with a factor of 1.125, leading to (height*1.125, width*1.125), then
a random crop is performed. Such operation is done with a probability.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>height</strong> (<em>int</em>) – target image height.</p></li>
<li><p><strong>width</strong> (<em>int</em>) – target image width.</p></li>
<li><p><strong>p</strong> (<em>float</em><em>, </em><em>optional</em>) – probability that this operation takes place.
Default is 0.5.</p></li>
<li><p><strong>interpolation</strong> (<em>int</em><em>, </em><em>optional</em>) – desired interpolation. Default is
<code class="docutils literal notranslate"><span class="pre">PIL.Image.BILINEAR</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="torchreid.data.transforms.RandomErasing">
<em class="property">class </em><code class="sig-prename descclassname">torchreid.data.transforms.</code><code class="sig-name descname">RandomErasing</code><span class="sig-paren">(</span><em class="sig-param">probability=0.5, sl=0.02, sh=0.4, r1=0.3, mean=[0.4914, 0.4822, 0.4465]</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/transforms.html#RandomErasing"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.transforms.RandomErasing" title="Permalink to this definition">¶</a></dt>
<dd><p>Randomly erases an image patch.</p>
<p>Origin: <a class="reference external" href="https://github.com/zhunzhong07/Random-Erasing">https://github.com/zhunzhong07/Random-Erasing</a></p>
<dl class="simple">
<dt>Reference:</dt><dd><p>Zhong et al. Random Erasing Data Augmentation.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>probability</strong> (<em>float</em><em>, </em><em>optional</em>) – probability that this operation takes place.
Default is 0.5.</p></li>
<li><p><strong>sl</strong> (<em>float</em><em>, </em><em>optional</em>) – min erasing area.</p></li>
<li><p><strong>sh</strong> (<em>float</em><em>, </em><em>optional</em>) – max erasing area.</p></li>
<li><p><strong>r1</strong> (<em>float</em><em>, </em><em>optional</em>) – min aspect ratio.</p></li>
<li><p><strong>mean</strong> (<em>list</em><em>, </em><em>optional</em>) – erasing value.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="torchreid.data.transforms.RandomPatch">
<em class="property">class </em><code class="sig-prename descclassname">torchreid.data.transforms.</code><code class="sig-name descname">RandomPatch</code><span class="sig-paren">(</span><em class="sig-param">prob_happen=0.5</em>, <em class="sig-param">pool_capacity=50000</em>, <em class="sig-param">min_sample_size=100</em>, <em class="sig-param">patch_min_area=0.01</em>, <em class="sig-param">patch_max_area=0.5</em>, <em class="sig-param">patch_min_ratio=0.1</em>, <em class="sig-param">prob_rotate=0.5</em>, <em class="sig-param">prob_flip_leftright=0.5</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/transforms.html#RandomPatch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.transforms.RandomPatch" title="Permalink to this definition">¶</a></dt>
<dd><p>Random patch data augmentation.</p>
<p>There is a patch pool that stores randomly extracted pathces from person images.</p>
<dl class="simple">
<dt>For each input image, RandomPatch</dt><dd><ol class="arabic simple">
<li><p>extracts a random patch and stores the patch in the patch pool;</p></li>
<li><p>randomly selects a patch from the patch pool and pastes it on the
input (at random position) to simulate occlusion.</p></li>
</ol>
</dd>
<dt>Reference:</dt><dd><ul class="simple">
<li><p>Zhou et al. Omni-Scale Feature Learning for Person Re-Identification. ICCV, 2019.</p></li>
<li><p>Zhou et al. Learning Generalisable Omni-Scale Representations
for Person Re-Identification. arXiv preprint, 2019.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="torchreid.data.transforms.build_transforms">
<code class="sig-prename descclassname">torchreid.data.transforms.</code><code class="sig-name descname">build_transforms</code><span class="sig-paren">(</span><em class="sig-param">height, width, transforms='random_flip', norm_mean=[0.485, 0.456, 0.406], norm_std=[0.229, 0.224, 0.225], **kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/transforms.html#build_transforms"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.transforms.build_transforms" title="Permalink to this definition">¶</a></dt>
<dd><p>Builds train and test transform functions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>height</strong> (<em>int</em>) – target image height.</p></li>
<li><p><strong>width</strong> (<em>int</em>) – target image width.</p></li>
<li><p><strong>transforms</strong> (<em>str</em><em> or </em><em>list of str</em><em>, </em><em>optional</em>) – transformations applied to model training.
Default is ‘random_flip’.</p></li>
<li><p><strong>norm_mean</strong> (<em>list</em><em> or </em><em>None</em><em>, </em><em>optional</em>) – normalization mean values. Default is ImageNet means.</p></li>
<li><p><strong>norm_std</strong> (<em>list</em><em> or </em><em>None</em><em>, </em><em>optional</em>) – normalization standard deviation values. Default is
ImageNet standard deviation values.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-torchreid.data.datasets.dataset">
<span id="dataset"></span><h2>Dataset<a class="headerlink" href="#module-torchreid.data.datasets.dataset" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchreid.data.datasets.dataset.Dataset">
<em class="property">class </em><code class="sig-prename descclassname">torchreid.data.datasets.dataset.</code><code class="sig-name descname">Dataset</code><span class="sig-paren">(</span><em class="sig-param">train</em>, <em class="sig-param">query</em>, <em class="sig-param">gallery</em>, <em class="sig-param">transform=None</em>, <em class="sig-param">k_tfm=1</em>, <em class="sig-param">mode='train'</em>, <em class="sig-param">combineall=False</em>, <em class="sig-param">verbose=True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/datasets/dataset.html#Dataset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.datasets.dataset.Dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>An abstract class representing a Dataset.</p>
<p>This is the base class for <code class="docutils literal notranslate"><span class="pre">ImageDataset</span></code> and <code class="docutils literal notranslate"><span class="pre">VideoDataset</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train</strong> (<em>list</em>) – contains tuples of (img_path(s), pid, camid).</p></li>
<li><p><strong>query</strong> (<em>list</em>) – contains tuples of (img_path(s), pid, camid).</p></li>
<li><p><strong>gallery</strong> (<em>list</em>) – contains tuples of (img_path(s), pid, camid).</p></li>
<li><p><strong>transform</strong> – transform function.</p></li>
<li><p><strong>k_tfm</strong> (<em>int</em>) – number of times to apply augmentation to an image
independently. If k_tfm &gt; 1, the transform function will be
applied k_tfm times to an image. This variable will only be
useful for training and is currently valid for image datasets only.</p></li>
<li><p><strong>mode</strong> (<em>str</em>) – ‘train’, ‘query’ or ‘gallery’.</p></li>
<li><p><strong>combineall</strong> (<em>bool</em>) – combines train, query and gallery in a
dataset for training.</p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) – show information.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torchreid.data.datasets.dataset.Dataset.check_before_run">
<code class="sig-name descname">check_before_run</code><span class="sig-paren">(</span><em class="sig-param">required_files</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/datasets/dataset.html#Dataset.check_before_run"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.datasets.dataset.Dataset.check_before_run" title="Permalink to this definition">¶</a></dt>
<dd><p>Checks if required files exist before going deeper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>required_files</strong> (<em>str</em><em> or </em><em>list</em>) – string file name(s).</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torchreid.data.datasets.dataset.Dataset.combine_all">
<code class="sig-name descname">combine_all</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/datasets/dataset.html#Dataset.combine_all"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.datasets.dataset.Dataset.combine_all" title="Permalink to this definition">¶</a></dt>
<dd><p>Combines train, query and gallery in a dataset for training.</p>
</dd></dl>

<dl class="method">
<dt id="torchreid.data.datasets.dataset.Dataset.download_dataset">
<code class="sig-name descname">download_dataset</code><span class="sig-paren">(</span><em class="sig-param">dataset_dir</em>, <em class="sig-param">dataset_url</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/datasets/dataset.html#Dataset.download_dataset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.datasets.dataset.Dataset.download_dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Downloads and extracts dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataset_dir</strong> (<em>str</em>) – dataset directory.</p></li>
<li><p><strong>dataset_url</strong> (<em>str</em>) – url to download dataset.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torchreid.data.datasets.dataset.Dataset.get_num_cams">
<code class="sig-name descname">get_num_cams</code><span class="sig-paren">(</span><em class="sig-param">data</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/datasets/dataset.html#Dataset.get_num_cams"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.datasets.dataset.Dataset.get_num_cams" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the number of training cameras.</p>
<p>Each tuple in data contains (img_path(s), pid, camid, dsetid).</p>
</dd></dl>

<dl class="method">
<dt id="torchreid.data.datasets.dataset.Dataset.get_num_datasets">
<code class="sig-name descname">get_num_datasets</code><span class="sig-paren">(</span><em class="sig-param">data</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/datasets/dataset.html#Dataset.get_num_datasets"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.datasets.dataset.Dataset.get_num_datasets" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the number of datasets included.</p>
<p>Each tuple in data contains (img_path(s), pid, camid, dsetid).</p>
</dd></dl>

<dl class="method">
<dt id="torchreid.data.datasets.dataset.Dataset.get_num_pids">
<code class="sig-name descname">get_num_pids</code><span class="sig-paren">(</span><em class="sig-param">data</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/datasets/dataset.html#Dataset.get_num_pids"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.datasets.dataset.Dataset.get_num_pids" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the number of training person identities.</p>
<p>Each tuple in data contains (img_path(s), pid, camid, dsetid).</p>
</dd></dl>

<dl class="method">
<dt id="torchreid.data.datasets.dataset.Dataset.show_summary">
<code class="sig-name descname">show_summary</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/datasets/dataset.html#Dataset.show_summary"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.datasets.dataset.Dataset.show_summary" title="Permalink to this definition">¶</a></dt>
<dd><p>Shows dataset statistics.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchreid.data.datasets.dataset.ImageDataset">
<em class="property">class </em><code class="sig-prename descclassname">torchreid.data.datasets.dataset.</code><code class="sig-name descname">ImageDataset</code><span class="sig-paren">(</span><em class="sig-param">train</em>, <em class="sig-param">query</em>, <em class="sig-param">gallery</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/datasets/dataset.html#ImageDataset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.datasets.dataset.ImageDataset" title="Permalink to this definition">¶</a></dt>
<dd><p>A base class representing ImageDataset.</p>
<p>All other image datasets should subclass it.</p>
<p><code class="docutils literal notranslate"><span class="pre">__getitem__</span></code> returns an image given index.
It will return <code class="docutils literal notranslate"><span class="pre">img</span></code>, <code class="docutils literal notranslate"><span class="pre">pid</span></code>, <code class="docutils literal notranslate"><span class="pre">camid</span></code> and <code class="docutils literal notranslate"><span class="pre">img_path</span></code>
where <code class="docutils literal notranslate"><span class="pre">img</span></code> has shape (channel, height, width). As a result,
data in each batch has shape (batch_size, channel, height, width).</p>
<dl class="method">
<dt id="torchreid.data.datasets.dataset.ImageDataset.show_summary">
<code class="sig-name descname">show_summary</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/datasets/dataset.html#ImageDataset.show_summary"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.datasets.dataset.ImageDataset.show_summary" title="Permalink to this definition">¶</a></dt>
<dd><p>Shows dataset statistics.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchreid.data.datasets.dataset.VideoDataset">
<em class="property">class </em><code class="sig-prename descclassname">torchreid.data.datasets.dataset.</code><code class="sig-name descname">VideoDataset</code><span class="sig-paren">(</span><em class="sig-param">train</em>, <em class="sig-param">query</em>, <em class="sig-param">gallery</em>, <em class="sig-param">seq_len=15</em>, <em class="sig-param">sample_method='evenly'</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/datasets/dataset.html#VideoDataset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.datasets.dataset.VideoDataset" title="Permalink to this definition">¶</a></dt>
<dd><p>A base class representing VideoDataset.</p>
<p>All other video datasets should subclass it.</p>
<p><code class="docutils literal notranslate"><span class="pre">__getitem__</span></code> returns an image given index.
It will return <code class="docutils literal notranslate"><span class="pre">imgs</span></code>, <code class="docutils literal notranslate"><span class="pre">pid</span></code> and <code class="docutils literal notranslate"><span class="pre">camid</span></code>
where <code class="docutils literal notranslate"><span class="pre">imgs</span></code> has shape (seq_len, channel, height, width). As a result,
data in each batch has shape (batch_size, seq_len, channel, height, width).</p>
<dl class="method">
<dt id="torchreid.data.datasets.dataset.VideoDataset.show_summary">
<code class="sig-name descname">show_summary</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/datasets/dataset.html#VideoDataset.show_summary"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.datasets.dataset.VideoDataset.show_summary" title="Permalink to this definition">¶</a></dt>
<dd><p>Shows dataset statistics.</p>
</dd></dl>

</dd></dl>

<span class="target" id="module-torchreid.data.datasets.__init__"></span><dl class="function">
<dt id="torchreid.data.datasets.__init__.init_image_dataset">
<code class="sig-prename descclassname">torchreid.data.datasets.__init__.</code><code class="sig-name descname">init_image_dataset</code><span class="sig-paren">(</span><em class="sig-param">name</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/datasets/__init__.html#init_image_dataset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.datasets.__init__.init_image_dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Initializes an image dataset.</p>
</dd></dl>

<dl class="function">
<dt id="torchreid.data.datasets.__init__.init_video_dataset">
<code class="sig-prename descclassname">torchreid.data.datasets.__init__.</code><code class="sig-name descname">init_video_dataset</code><span class="sig-paren">(</span><em class="sig-param">name</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/datasets/__init__.html#init_video_dataset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.datasets.__init__.init_video_dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Initializes a video dataset.</p>
</dd></dl>

<dl class="function">
<dt id="torchreid.data.datasets.__init__.register_image_dataset">
<code class="sig-prename descclassname">torchreid.data.datasets.__init__.</code><code class="sig-name descname">register_image_dataset</code><span class="sig-paren">(</span><em class="sig-param">name</em>, <em class="sig-param">dataset</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/datasets/__init__.html#register_image_dataset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.datasets.__init__.register_image_dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a new image dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) – key corresponding to the new dataset.</p></li>
<li><p><strong>dataset</strong> (<a class="reference internal" href="#torchreid.data.datasets.dataset.Dataset" title="torchreid.data.datasets.dataset.Dataset"><em>Dataset</em></a>) – the new dataset class.</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torchreid</span>
<span class="kn">import</span> <span class="nn">NewDataset</span>
<span class="n">torchreid</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">register_image_dataset</span><span class="p">(</span><span class="s1">&#39;new_dataset&#39;</span><span class="p">,</span> <span class="n">NewDataset</span><span class="p">)</span>
<span class="c1"># single dataset case</span>
<span class="n">datamanager</span> <span class="o">=</span> <span class="n">torchreid</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">ImageDataManager</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="s1">&#39;reid-data&#39;</span><span class="p">,</span>
    <span class="n">sources</span><span class="o">=</span><span class="s1">&#39;new_dataset&#39;</span>
<span class="p">)</span>
<span class="c1"># multiple dataset case</span>
<span class="n">datamanager</span> <span class="o">=</span> <span class="n">torchreid</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">ImageDataManager</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="s1">&#39;reid-data&#39;</span><span class="p">,</span>
    <span class="n">sources</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;new_dataset&#39;</span><span class="p">,</span> <span class="s1">&#39;dukemtmcreid&#39;</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torchreid.data.datasets.__init__.register_video_dataset">
<code class="sig-prename descclassname">torchreid.data.datasets.__init__.</code><code class="sig-name descname">register_video_dataset</code><span class="sig-paren">(</span><em class="sig-param">name</em>, <em class="sig-param">dataset</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/datasets/__init__.html#register_video_dataset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.datasets.__init__.register_video_dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a new video dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) – key corresponding to the new dataset.</p></li>
<li><p><strong>dataset</strong> (<a class="reference internal" href="#torchreid.data.datasets.dataset.Dataset" title="torchreid.data.datasets.dataset.Dataset"><em>Dataset</em></a>) – the new dataset class.</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torchreid</span>
<span class="kn">import</span> <span class="nn">NewDataset</span>
<span class="n">torchreid</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">register_video_dataset</span><span class="p">(</span><span class="s1">&#39;new_dataset&#39;</span><span class="p">,</span> <span class="n">NewDataset</span><span class="p">)</span>
<span class="c1"># single dataset case</span>
<span class="n">datamanager</span> <span class="o">=</span> <span class="n">torchreid</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">VideoDataManager</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="s1">&#39;reid-data&#39;</span><span class="p">,</span>
    <span class="n">sources</span><span class="o">=</span><span class="s1">&#39;new_dataset&#39;</span>
<span class="p">)</span>
<span class="c1"># multiple dataset case</span>
<span class="n">datamanager</span> <span class="o">=</span> <span class="n">torchreid</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">VideoDataManager</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="s1">&#39;reid-data&#39;</span><span class="p">,</span>
    <span class="n">sources</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;new_dataset&#39;</span><span class="p">,</span> <span class="s1">&#39;ilidsvid&#39;</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="module-torchreid.data.datasets.image.market1501">
<span id="image-datasets"></span><h2>Image Datasets<a class="headerlink" href="#module-torchreid.data.datasets.image.market1501" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchreid.data.datasets.image.market1501.Market1501">
<em class="property">class </em><code class="sig-prename descclassname">torchreid.data.datasets.image.market1501.</code><code class="sig-name descname">Market1501</code><span class="sig-paren">(</span><em class="sig-param">root=''</em>, <em class="sig-param">market1501_500k=False</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/datasets/image/market1501.html#Market1501"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.datasets.image.market1501.Market1501" title="Permalink to this definition">¶</a></dt>
<dd><p>Market1501.</p>
<dl class="simple">
<dt>Reference:</dt><dd><p>Zheng et al. Scalable Person Re-identification: A Benchmark. ICCV 2015.</p>
</dd>
</dl>
<p>URL: <a class="reference external" href="http://www.liangzheng.org/Project/project_reid.html">http://www.liangzheng.org/Project/project_reid.html</a></p>
<dl class="simple">
<dt>Dataset statistics:</dt><dd><ul class="simple">
<li><p>identities: 1501 (+1 for background).</p></li>
<li><p>images: 12936 (train) + 3368 (query) + 15913 (gallery).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<span class="target" id="module-torchreid.data.datasets.image.cuhk03"></span><dl class="class">
<dt id="torchreid.data.datasets.image.cuhk03.CUHK03">
<em class="property">class </em><code class="sig-prename descclassname">torchreid.data.datasets.image.cuhk03.</code><code class="sig-name descname">CUHK03</code><span class="sig-paren">(</span><em class="sig-param">root=''</em>, <em class="sig-param">split_id=0</em>, <em class="sig-param">cuhk03_labeled=False</em>, <em class="sig-param">cuhk03_classic_split=False</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/datasets/image/cuhk03.html#CUHK03"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.datasets.image.cuhk03.CUHK03" title="Permalink to this definition">¶</a></dt>
<dd><p>CUHK03.</p>
<dl class="simple">
<dt>Reference:</dt><dd><p>Li et al. DeepReID: Deep Filter Pairing Neural Network for Person Re-identification. CVPR 2014.</p>
</dd>
</dl>
<p>URL: <a class="reference external" href="http://www.ee.cuhk.edu.hk/~xgwang/CUHK_identification.html#!">http://www.ee.cuhk.edu.hk/~xgwang/CUHK_identification.html#!</a></p>
<dl class="simple">
<dt>Dataset statistics:</dt><dd><ul class="simple">
<li><p>identities: 1360.</p></li>
<li><p>images: 13164.</p></li>
<li><p>cameras: 6.</p></li>
<li><p>splits: 20 (classic).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<span class="target" id="module-torchreid.data.datasets.image.dukemtmcreid"></span><dl class="class">
<dt id="torchreid.data.datasets.image.dukemtmcreid.DukeMTMCreID">
<em class="property">class </em><code class="sig-prename descclassname">torchreid.data.datasets.image.dukemtmcreid.</code><code class="sig-name descname">DukeMTMCreID</code><span class="sig-paren">(</span><em class="sig-param">root=''</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/datasets/image/dukemtmcreid.html#DukeMTMCreID"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.datasets.image.dukemtmcreid.DukeMTMCreID" title="Permalink to this definition">¶</a></dt>
<dd><p>DukeMTMC-reID.</p>
<dl class="simple">
<dt>Reference:</dt><dd><ul class="simple">
<li><p>Ristani et al. Performance Measures and a Data Set for Multi-Target, Multi-Camera Tracking. ECCVW 2016.</p></li>
<li><p>Zheng et al. Unlabeled Samples Generated by GAN Improve the Person Re-identification Baseline in vitro. ICCV 2017.</p></li>
</ul>
</dd>
</dl>
<p>URL: <a class="reference external" href="https://github.com/layumi/DukeMTMC-reID_evaluation">https://github.com/layumi/DukeMTMC-reID_evaluation</a></p>
<dl class="simple">
<dt>Dataset statistics:</dt><dd><ul class="simple">
<li><p>identities: 1404 (train + query).</p></li>
<li><p>images:16522 (train) + 2228 (query) + 17661 (gallery).</p></li>
<li><p>cameras: 8.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<span class="target" id="module-torchreid.data.datasets.image.msmt17"></span><dl class="class">
<dt id="torchreid.data.datasets.image.msmt17.MSMT17">
<em class="property">class </em><code class="sig-prename descclassname">torchreid.data.datasets.image.msmt17.</code><code class="sig-name descname">MSMT17</code><span class="sig-paren">(</span><em class="sig-param">root=''</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/datasets/image/msmt17.html#MSMT17"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.datasets.image.msmt17.MSMT17" title="Permalink to this definition">¶</a></dt>
<dd><p>MSMT17.</p>
<dl class="simple">
<dt>Reference:</dt><dd><p>Wei et al. Person Transfer GAN to Bridge Domain Gap for Person Re-Identification. CVPR 2018.</p>
</dd>
</dl>
<p>URL: <a class="reference external" href="http://www.pkuvmc.com/publications/msmt17.html">http://www.pkuvmc.com/publications/msmt17.html</a></p>
<dl class="simple">
<dt>Dataset statistics:</dt><dd><ul class="simple">
<li><p>identities: 4101.</p></li>
<li><p>images: 32621 (train) + 11659 (query) + 82161 (gallery).</p></li>
<li><p>cameras: 15.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<span class="target" id="module-torchreid.data.datasets.image.viper"></span><dl class="class">
<dt id="torchreid.data.datasets.image.viper.VIPeR">
<em class="property">class </em><code class="sig-prename descclassname">torchreid.data.datasets.image.viper.</code><code class="sig-name descname">VIPeR</code><span class="sig-paren">(</span><em class="sig-param">root=''</em>, <em class="sig-param">split_id=0</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/datasets/image/viper.html#VIPeR"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.datasets.image.viper.VIPeR" title="Permalink to this definition">¶</a></dt>
<dd><p>VIPeR.</p>
<dl class="simple">
<dt>Reference:</dt><dd><p>Gray et al. Evaluating appearance models for recognition, reacquisition, and tracking. PETS 2007.</p>
</dd>
</dl>
<p>URL: <a class="reference external" href="https://vision.soe.ucsc.edu/node/178">https://vision.soe.ucsc.edu/node/178</a></p>
<dl class="simple">
<dt>Dataset statistics:</dt><dd><ul class="simple">
<li><p>identities: 632.</p></li>
<li><p>images: 632 x 2 = 1264.</p></li>
<li><p>cameras: 2.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<span class="target" id="module-torchreid.data.datasets.image.grid"></span><dl class="class">
<dt id="torchreid.data.datasets.image.grid.GRID">
<em class="property">class </em><code class="sig-prename descclassname">torchreid.data.datasets.image.grid.</code><code class="sig-name descname">GRID</code><span class="sig-paren">(</span><em class="sig-param">root=''</em>, <em class="sig-param">split_id=0</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/datasets/image/grid.html#GRID"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.datasets.image.grid.GRID" title="Permalink to this definition">¶</a></dt>
<dd><p>GRID.</p>
<dl class="simple">
<dt>Reference:</dt><dd><p>Loy et al. Multi-camera activity correlation analysis. CVPR 2009.</p>
</dd>
</dl>
<p>URL: <a class="reference external" href="http://personal.ie.cuhk.edu.hk/~ccloy/downloads_qmul_underground_reid.html">http://personal.ie.cuhk.edu.hk/~ccloy/downloads_qmul_underground_reid.html</a></p>
<dl class="simple">
<dt>Dataset statistics:</dt><dd><ul class="simple">
<li><p>identities: 250.</p></li>
<li><p>images: 1275.</p></li>
<li><p>cameras: 8.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<span class="target" id="module-torchreid.data.datasets.image.cuhk01"></span><dl class="class">
<dt id="torchreid.data.datasets.image.cuhk01.CUHK01">
<em class="property">class </em><code class="sig-prename descclassname">torchreid.data.datasets.image.cuhk01.</code><code class="sig-name descname">CUHK01</code><span class="sig-paren">(</span><em class="sig-param">root=''</em>, <em class="sig-param">split_id=0</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/datasets/image/cuhk01.html#CUHK01"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.datasets.image.cuhk01.CUHK01" title="Permalink to this definition">¶</a></dt>
<dd><p>CUHK01.</p>
<dl class="simple">
<dt>Reference:</dt><dd><p>Li et al. Human Reidentification with Transferred Metric Learning. ACCV 2012.</p>
</dd>
</dl>
<p>URL: <a class="reference external" href="http://www.ee.cuhk.edu.hk/~xgwang/CUHK_identification.html">http://www.ee.cuhk.edu.hk/~xgwang/CUHK_identification.html</a></p>
<dl class="simple">
<dt>Dataset statistics:</dt><dd><ul class="simple">
<li><p>identities: 971.</p></li>
<li><p>images: 3884.</p></li>
<li><p>cameras: 4.</p></li>
</ul>
</dd>
</dl>
<p>Note: CUHK01 and CUHK02 overlap.</p>
<dl class="method">
<dt id="torchreid.data.datasets.image.cuhk01.CUHK01.prepare_split">
<code class="sig-name descname">prepare_split</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/datasets/image/cuhk01.html#CUHK01.prepare_split"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.datasets.image.cuhk01.CUHK01.prepare_split" title="Permalink to this definition">¶</a></dt>
<dd><p>Image name format: 0001001.png, where first four digits represent identity
and last four digits represent cameras. Camera 1&amp;2 are considered the same
view and camera 3&amp;4 are considered the same view.</p>
</dd></dl>

</dd></dl>

<span class="target" id="module-torchreid.data.datasets.image.ilids"></span><dl class="class">
<dt id="torchreid.data.datasets.image.ilids.iLIDS">
<em class="property">class </em><code class="sig-prename descclassname">torchreid.data.datasets.image.ilids.</code><code class="sig-name descname">iLIDS</code><span class="sig-paren">(</span><em class="sig-param">root=''</em>, <em class="sig-param">split_id=0</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/datasets/image/ilids.html#iLIDS"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.datasets.image.ilids.iLIDS" title="Permalink to this definition">¶</a></dt>
<dd><p>QMUL-iLIDS.</p>
<dl class="simple">
<dt>Reference:</dt><dd><p>Zheng et al. Associating Groups of People. BMVC 2009.</p>
</dd>
<dt>Dataset statistics:</dt><dd><ul class="simple">
<li><p>identities: 119.</p></li>
<li><p>images: 476.</p></li>
<li><p>cameras: 8 (not explicitly provided).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<span class="target" id="module-torchreid.data.datasets.image.sensereid"></span><dl class="class">
<dt id="torchreid.data.datasets.image.sensereid.SenseReID">
<em class="property">class </em><code class="sig-prename descclassname">torchreid.data.datasets.image.sensereid.</code><code class="sig-name descname">SenseReID</code><span class="sig-paren">(</span><em class="sig-param">root=''</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/datasets/image/sensereid.html#SenseReID"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.datasets.image.sensereid.SenseReID" title="Permalink to this definition">¶</a></dt>
<dd><p>SenseReID.</p>
<p>This dataset is used for test purpose only.</p>
<dl class="simple">
<dt>Reference:</dt><dd><p>Zhao et al. Spindle Net: Person Re-identification with Human Body
Region Guided Feature Decomposition and Fusion. CVPR 2017.</p>
</dd>
</dl>
<p>URL: <a class="reference external" href="https://drive.google.com/file/d/0B56OfSrVI8hubVJLTzkwV2VaOWM/view">https://drive.google.com/file/d/0B56OfSrVI8hubVJLTzkwV2VaOWM/view</a></p>
<dl class="simple">
<dt>Dataset statistics:</dt><dd><ul class="simple">
<li><p>query: 522 ids, 1040 images.</p></li>
<li><p>gallery: 1717 ids, 3388 images.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<span class="target" id="module-torchreid.data.datasets.image.prid"></span><dl class="class">
<dt id="torchreid.data.datasets.image.prid.PRID">
<em class="property">class </em><code class="sig-prename descclassname">torchreid.data.datasets.image.prid.</code><code class="sig-name descname">PRID</code><span class="sig-paren">(</span><em class="sig-param">single-shot version of prid-2011</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/datasets/image/prid.html#PRID"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.datasets.image.prid.PRID" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Reference:</dt><dd><p>Hirzer et al. Person Re-Identification by Descriptive and Discriminative
Classification. SCIA 2011.</p>
</dd>
</dl>
<p>URL: <a class="reference external" href="https://www.tugraz.at/institute/icg/research/team-bischof/lrs/downloads/PRID11/">https://www.tugraz.at/institute/icg/research/team-bischof/lrs/downloads/PRID11/</a></p>
<dl class="simple">
<dt>Dataset statistics:</dt><dd><ul class="simple">
<li><p>Two views.</p></li>
<li><p>View A captures 385 identities.</p></li>
<li><p>View B captures 749 identities.</p></li>
<li><p>200 identities appear in both views (index starts from 1 to 200).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-torchreid.data.datasets.video.mars">
<span id="video-datasets"></span><h2>Video Datasets<a class="headerlink" href="#module-torchreid.data.datasets.video.mars" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchreid.data.datasets.video.mars.Mars">
<em class="property">class </em><code class="sig-prename descclassname">torchreid.data.datasets.video.mars.</code><code class="sig-name descname">Mars</code><span class="sig-paren">(</span><em class="sig-param">root=''</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/datasets/video/mars.html#Mars"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.datasets.video.mars.Mars" title="Permalink to this definition">¶</a></dt>
<dd><p>MARS.</p>
<dl class="simple">
<dt>Reference:</dt><dd><p>Zheng et al. MARS: A Video Benchmark for Large-Scale Person Re-identification. ECCV 2016.</p>
</dd>
</dl>
<p>URL: <a class="reference external" href="http://www.liangzheng.com.cn/Project/project_mars.html">http://www.liangzheng.com.cn/Project/project_mars.html</a></p>
<dl class="simple">
<dt>Dataset statistics:</dt><dd><ul class="simple">
<li><p>identities: 1261.</p></li>
<li><p>tracklets: 8298 (train) + 1980 (query) + 9330 (gallery).</p></li>
<li><p>cameras: 6.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torchreid.data.datasets.video.mars.Mars.combine_all">
<code class="sig-name descname">combine_all</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/datasets/video/mars.html#Mars.combine_all"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.datasets.video.mars.Mars.combine_all" title="Permalink to this definition">¶</a></dt>
<dd><p>Combines train, query and gallery in a dataset for training.</p>
</dd></dl>

</dd></dl>

<span class="target" id="module-torchreid.data.datasets.video.ilidsvid"></span><dl class="class">
<dt id="torchreid.data.datasets.video.ilidsvid.iLIDSVID">
<em class="property">class </em><code class="sig-prename descclassname">torchreid.data.datasets.video.ilidsvid.</code><code class="sig-name descname">iLIDSVID</code><span class="sig-paren">(</span><em class="sig-param">root=''</em>, <em class="sig-param">split_id=0</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/datasets/video/ilidsvid.html#iLIDSVID"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.datasets.video.ilidsvid.iLIDSVID" title="Permalink to this definition">¶</a></dt>
<dd><p>iLIDS-VID.</p>
<dl class="simple">
<dt>Reference:</dt><dd><p>Wang et al. Person Re-Identification by Video Ranking. ECCV 2014.</p>
</dd>
</dl>
<p>URL: <a class="reference external" href="http://www.eecs.qmul.ac.uk/~xiatian/downloads_qmul_iLIDS-VID_ReID_dataset.html">http://www.eecs.qmul.ac.uk/~xiatian/downloads_qmul_iLIDS-VID_ReID_dataset.html</a></p>
<dl class="simple">
<dt>Dataset statistics:</dt><dd><ul class="simple">
<li><p>identities: 300.</p></li>
<li><p>tracklets: 600.</p></li>
<li><p>cameras: 2.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<span class="target" id="module-torchreid.data.datasets.video.prid2011"></span><dl class="class">
<dt id="torchreid.data.datasets.video.prid2011.PRID2011">
<em class="property">class </em><code class="sig-prename descclassname">torchreid.data.datasets.video.prid2011.</code><code class="sig-name descname">PRID2011</code><span class="sig-paren">(</span><em class="sig-param">root=''</em>, <em class="sig-param">split_id=0</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/datasets/video/prid2011.html#PRID2011"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.datasets.video.prid2011.PRID2011" title="Permalink to this definition">¶</a></dt>
<dd><p>PRID2011.</p>
<dl class="simple">
<dt>Reference:</dt><dd><p>Hirzer et al. Person Re-Identification by Descriptive and
Discriminative Classification. SCIA 2011.</p>
</dd>
</dl>
<p>URL: <a class="reference external" href="https://www.tugraz.at/institute/icg/research/team-bischof/lrs/downloads/PRID11/">https://www.tugraz.at/institute/icg/research/team-bischof/lrs/downloads/PRID11/</a></p>
<dl class="simple">
<dt>Dataset statistics:</dt><dd><ul class="simple">
<li><p>identities: 200.</p></li>
<li><p>tracklets: 400.</p></li>
<li><p>cameras: 2.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<span class="target" id="module-torchreid.data.datasets.video.dukemtmcvidreid"></span><dl class="class">
<dt id="torchreid.data.datasets.video.dukemtmcvidreid.DukeMTMCVidReID">
<em class="property">class </em><code class="sig-prename descclassname">torchreid.data.datasets.video.dukemtmcvidreid.</code><code class="sig-name descname">DukeMTMCVidReID</code><span class="sig-paren">(</span><em class="sig-param">root=''</em>, <em class="sig-param">min_seq_len=0</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torchreid/data/datasets/video/dukemtmcvidreid.html#DukeMTMCVidReID"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchreid.data.datasets.video.dukemtmcvidreid.DukeMTMCVidReID" title="Permalink to this definition">¶</a></dt>
<dd><p>DukeMTMCVidReID.</p>
<dl class="simple">
<dt>Reference:</dt><dd><ul class="simple">
<li><p>Ristani et al. Performance Measures and a Data Set for Multi-Target,
Multi-Camera Tracking. ECCVW 2016.</p></li>
<li><p>Wu et al. Exploit the Unknown Gradually: One-Shot Video-Based Person
Re-Identification by Stepwise Learning. CVPR 2018.</p></li>
</ul>
</dd>
</dl>
<p>URL: <a class="reference external" href="https://github.com/Yu-Wu/DukeMTMC-VideoReID">https://github.com/Yu-Wu/DukeMTMC-VideoReID</a></p>
<dl class="simple">
<dt>Dataset statistics:</dt><dd><ul class="simple">
<li><p>identities: 702 (train) + 702 (test).</p></li>
<li><p>tracklets: 2196 (train) + 2636 (test).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="engine.html" class="btn btn-neutral float-right" title="torchreid.engine" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../evaluation.html" class="btn btn-neutral float-left" title="Evaluation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2019, Kaiyang Zhou

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>